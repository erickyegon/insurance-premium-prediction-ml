[2026-01-08 11:36:35,313] 614  root - INFO - Running model_trainer as a script.
[2026-01-08 11:36:35,314] 681  root - INFO - Starting data transformation pipeline.
[2026-01-08 11:36:35,338] 689  root - INFO - Loaded train shape: (8000, 15)
[2026-01-08 11:36:35,338] 690  root - INFO - Loaded test shape:  (2000, 15)
[2026-01-08 11:36:35,338] 487  root - INFO - [train] Standardizing column names.
[2026-01-08 11:36:35,340] 487  root - INFO - [test] Standardizing column names.
[2026-01-08 11:36:35,341] 705  root - INFO - Cleaning enabled.
[2026-01-08 11:36:35,341] 232  root - INFO - Missing-value strategy=keep: leaving NA for pipeline imputers.
[2026-01-08 11:36:35,344] 232  root - INFO - Missing-value strategy=keep: leaving NA for pipeline imputers.
[2026-01-08 11:36:35,351] 241  root - INFO - Dropped 0 duplicate rows.
[2026-01-08 11:36:35,354] 241  root - INFO - Dropped 0 duplicate rows.
[2026-01-08 11:36:35,354] 718  root - INFO - Feature engineering enabled.
[2026-01-08 11:36:35,364] 764  root - INFO - EDA enabled; saving diagnostic artifacts.
[2026-01-08 11:36:35,364] 320  root - INFO - EDA started for train.
[2026-01-08 11:36:35,397] 325  root - INFO - Saved stats summary: artifacts\eda\train_stats_summary.csv
[2026-01-08 11:36:35,411] 336  root - INFO - Saved missingness report: artifacts\eda\train_missingness.csv
[2026-01-08 11:36:35,817] 355  root - INFO - Saved boxplot: artifacts\eda\train_outliers_boxplot.png
[2026-01-08 11:36:35,830] 362  root - INFO - Saved correlation CSV: artifacts\eda\train_correlation.csv
[2026-01-08 11:36:35,831] 364  root - INFO - EDA completed for train.
[2026-01-08 11:36:35,831] 320  root - INFO - EDA started for test.
[2026-01-08 11:36:35,864] 325  root - INFO - Saved stats summary: artifacts\eda\test_stats_summary.csv
[2026-01-08 11:36:35,872] 336  root - INFO - Saved missingness report: artifacts\eda\test_missingness.csv
[2026-01-08 11:36:36,144] 355  root - INFO - Saved boxplot: artifacts\eda\test_outliers_boxplot.png
[2026-01-08 11:36:36,148] 362  root - INFO - Saved correlation CSV: artifacts\eda\test_correlation.csv
[2026-01-08 11:36:36,148] 364  root - INFO - EDA completed for test.
[2026-01-08 11:36:36,149] 772  root - INFO - VIF enabled; checking multicollinearity on numeric predictors.
[2026-01-08 11:36:36,157] 628  root - INFO - Saved VIF report: artifacts\vif_report.csv
[2026-01-08 11:36:36,163] 801  root - INFO - Selected numeric features (3): ['age', 'number_of_dependants', 'income_lakhs']
[2026-01-08 11:36:36,164] 802  root - INFO - Selected categorical features (10): ['gender', 'region', 'marital_status', 'physical_activity', 'stress_level', 'bmi_category', 'smoking_status', 'employment_status', 'medical_history', 'insurance_plan']
[2026-01-08 11:36:36,164] 803  root - INFO - Target column: annual_premium_amount
[2026-01-08 11:36:36,164] 813  root - INFO - Fitting preprocessor on training data only.
[2026-01-08 11:36:36,207] 843  root - INFO - Saved preprocessor: artifacts\preprocessor.pkl
[2026-01-08 11:36:36,208] 844  root - INFO - Saved transformed train: artifacts\train_transformed.npy
[2026-01-08 11:36:36,208] 845  root - INFO - Saved transformed test:  artifacts\test_transformed.npy
[2026-01-08 11:36:36,208] 846  root - INFO - Transformation done. Train arr: (8000, 40) | Test arr: (2000, 40)
[2026-01-08 11:36:36,209] 628  root - INFO - Preprocessor used: artifacts\preprocessor.pkl
[2026-01-08 11:36:36,209] 469  root - INFO - Starting model training pipeline.
[2026-01-08 11:36:36,209] 476  root - INFO - Train(full): X=(8000, 39) y=(8000,)
[2026-01-08 11:36:36,209] 477  root - INFO - Test:       X=(2000, 39) y=(2000,)
[2026-01-08 11:36:36,211] 486  root - INFO - Internal split -> Train=(6400, 39) | Val=(1600, 39)
[2026-01-08 11:36:36,213] 501  root - INFO - Training baseline: LinearRegression
[2026-01-08 11:36:36,225] 509  root - INFO - Training baseline: Ridge
[2026-01-08 11:36:36,229] 518  root - INFO - Training baseline: Lasso
[2026-01-08 11:36:36,432] 310  root - INFO - Running RandomizedSearchCV for XGBoost (n_iter=20, cv=3).
[2026-01-08 11:36:57,273] 315  root - INFO - XGBoost best params: {'subsample': 1.0, 'reg_lambda': 1.0, 'reg_alpha': 0.01, 'n_estimators': 300, 'min_child_weight': 5, 'max_depth': 3, 'learning_rate': 0.2, 'colsample_bytree': 0.7}
[2026-01-08 11:36:57,274] 316  root - INFO - XGBoost best CV score: 0.993110
[2026-01-08 11:36:57,274] 319  root - INFO - Attempting early-stopping refinement (best model).
[2026-01-08 11:36:57,274] 341  root - WARNING - Early stopping not supported; keeping CV-best model.
[2026-01-08 11:36:57,281] 546  root - INFO - Saved leaderboard: artifacts\model_leaderboard.csv
[2026-01-08 11:36:57,287] 552  root - INFO - Saved winner model: artifacts\model.pkl
[2026-01-08 11:36:57,312] 170  root - INFO - Saved notebook-style results_df: artifacts\results_predictions.csv
[2026-01-08 11:36:57,994] 241  root - INFO - Saved residual plots: artifacts\residual_hist.png | artifacts\residual_scatter.png
[2026-01-08 11:36:58,418] 260  root - INFO - Saved seaborn residual histplot: artifacts\residual_hist_seaborn.png
[2026-01-08 11:36:58,424] 206  root - INFO - Saved feature_importances_ to: artifacts\feature_importance.csv
[2026-01-08 11:36:59,380] 395  root - INFO - Running SHAP TreeExplainer: background=(500, 39), explain=(1000, 39)
[2026-01-08 11:36:59,405] 601  root - ERROR - Model training pipeline failed.
Traceback (most recent call last):
  File "C:\2026 Projects\Shield Insurance\src\components\model_trainer.py", line 568, in initiate_model_trainer
    self._run_shap_analysis(
  File "C:\2026 Projects\Shield Insurance\src\components\model_trainer.py", line 398, in _run_shap_analysis
    explainer = shap.TreeExplainer(model, data=X_bg)
  File "C:\2026 Projects\Shield Insurance\venv\lib\site-packages\shap\explainers\_tree.py", line 278, in __init__
    self.model = TreeEnsemble(model, self.data, self.data_missing, model_output)
  File "C:\2026 Projects\Shield Insurance\venv\lib\site-packages\shap\explainers\_tree.py", line 1279, in __init__
    self._set_xgboost_model_attributes(
  File "C:\2026 Projects\Shield Insurance\venv\lib\site-packages\shap\explainers\_tree.py", line 1506, in _set_xgboost_model_attributes
    loader = XGBTreeModelLoader(self.original_model)
  File "C:\2026 Projects\Shield Insurance\venv\lib\site-packages\shap\explainers\_tree.py", line 2104, in __init__
    self.base_score = float(learner_model_param["base_score"])
ValueError: could not convert string to float: '[1.9488639E4]'
